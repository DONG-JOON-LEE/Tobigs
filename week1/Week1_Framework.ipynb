{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1_Library 과제"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Library 와 Framework 의 차이 간단하게 서술하시오. (100자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framework : 애플리케이션 개발 시 필수적인 코드, 알고리즘, DB연동과 같은 기능들을 위해 어느정도의 구조를 갖춘 도구  \n",
    "Library : sw를 개발할 때 컴퓨터 프로그램이 사용하는 비휘발성 자원의 모임, 특정 기능을 모아둔 코드, 함수들의 집합"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2. 딥러닝과 머신러닝의 관계 및 특징, 차이 간단하게 서술하시오. (200자 내외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝 : 사람이 정한 모델과 특징 추출 방법을 사용하여 데이터를 기반으로 학습해 추론할 수 있게 하는 기술  \n",
    "딥러닝 : 신경망을 통해 인공지능을 만드는 머신러닝의 한 종류로 Multi-layer-perceptron의 방식으로 구현됨\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. 아래의 코드에 주석 달기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#library and device setting \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transfroms\n",
    "\n",
    "device = torch.device('mps')\n",
    "torch.manual_seed(45)\n",
    "if device == 'mps':\n",
    "    torch.cuda.manual_seed_all(45)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter setting\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 9873807.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 6693319.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 5129273.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 975249.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#torchvision에서 MNIST dataset 불러오기 \n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor() #tensor로 변환 \n",
    "    ])\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    root = './data/MNIST',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = transfroms.Compose([\n",
    "        transfroms.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch 학습을 위한 DataLoader setting \n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "#data 미리보기 \n",
    "examples = enumerate(train_set)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network setting\n",
    "class ConvNet(nn.Module): #torch.module을 상속받아 convolution network만들기 \n",
    "  def __init__(self): \n",
    "        super(ConvNet, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)        #convolution network 1 \n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)       #convolution network 2\n",
    "        self.drop2D = nn.Dropout2d(p=0.25, inplace=False)   #dropout \n",
    "        self.mp = nn.MaxPool2d(2)                           #maxpooling\n",
    "        self.fc1 = nn.Linear(320,100)                       #fc-layer\n",
    "        self.fc2 = nn.Linear(100,10)                        #fc-layer\n",
    "\n",
    "\n",
    "  def forward(self, x): #forward propagation을 위한 network \n",
    "        x = F.relu(self.mp(self.conv1(x))) \n",
    "        x = F.relu(self.mp(self.conv2(x))) \n",
    "        x = self.drop2D(x) \n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model instance\n",
    "model = ConvNet().to(device)\n",
    "#loss function setting \n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "#optimizer setting \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r2/dldm7t_d37nfdthx_29x_thc0000gn/T/ipykernel_4876/3803583406.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1]  cost = 0.329498947\n",
      "[Epoch:    2]  cost = 0.110761248\n",
      "[Epoch:    3]  cost = 0.0862471685\n",
      "[Epoch:    4]  cost = 0.0730262101\n",
      "[Epoch:    5]  cost = 0.0654386058\n"
     ]
    }
   ],
   "source": [
    "#train \n",
    "for epoch in range(epochs): \n",
    "    avg_cost = 0\n",
    "    for data, target in train_loader: #train_loader로 부터 batch 단위로 data 받기\n",
    "        data = data.to(device)        #data -> mps\n",
    "        target = target.to(device)    #target -> mps\n",
    "        optimizer.zero_grad()         #weight initialization\n",
    "        hypothesis = model(data)      \n",
    "        cost = criterion(hypothesis, target) #loss function \n",
    "        cost.backward()                      #back propagation\n",
    "        optimizer.step()                     #weight 갱신\n",
    "        avg_cost += cost / len(train_loader) #average cost계산\n",
    "    print('[Epoch: {:>4}]  cost = {:>.9}'.format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r2/dldm7t_d37nfdthx_29x_thc0000gn/T/ipykernel_4876/3803583406.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  98.64 %\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "model.eval()\n",
    "with torch.no_grad(): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data, target in test_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        out = model(data)\n",
    "        preds = torch.max(out.data, 1)[1] \n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item() \n",
    "        \n",
    "    print('Test Accuracy: ', 100.*correct/total, '%')\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:28:41) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1f139bfe50863fdc3f63778d5a835db5a3777731fa746cdee93d5ecfb549fd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
